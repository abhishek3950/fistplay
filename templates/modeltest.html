<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rock Paper Scissors Detection with MediaPipe</title>
  <link rel="stylesheet" type="text/css" href="/static/css/styles.css">
</head>
<body>
  <h1>Rock Paper Scissors Detection Test</h1>
  <div id="countdown">Countdown: 5</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="capturedFrame"></canvas>
  <p id="prediction">Prediction: ...</p>
  <button id="restart">Restart</button>

  <!-- MediaPipe and TensorFlow.js scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0"></script>

  <script>
    const video = document.getElementById('video');
    const capturedCanvas = document.getElementById('capturedFrame');
    const capturedCtx = capturedCanvas.getContext('2d');
    const predictionText = document.getElementById('prediction');
    const countdownText = document.getElementById('countdown');
    const restartButton = document.getElementById('restart');
    let countdown = 5;
    let countdownInterval;

    // Initialize MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });
    hands.setOptions({
      maxNumHands: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    hands.onResults(onResults);

    // Function to handle MediaPipe results
    function onResults(results) {
      if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) {
        predictionText.innerText = "Prediction: No hand detected";
        return;
      }

      // Display the captured frame
      capturedCanvas.width = video.videoWidth;
      capturedCanvas.height = video.videoHeight;
      capturedCtx.drawImage(video, 0, 0, capturedCanvas.width, capturedCanvas.height);

      const landmarks = results.multiHandLandmarks[0];
      const thumbTip = landmarks[4];
      const indexTip = landmarks[8];
      const middleTip = landmarks[12];
      const ringTip = landmarks[16];
      const pinkyTip = landmarks[20];

      let gesture = "Unknown";

      // Simple logic to recognize rock, paper, scissors based on finger positions
      if (indexTip.y > thumbTip.y && middleTip.y > thumbTip.y && ringTip.y > thumbTip.y && pinkyTip.y > thumbTip.y) {
        gesture = "Rock";
      } else if (indexTip.y < thumbTip.y && middleTip.y < thumbTip.y && ringTip.y < thumbTip.y && pinkyTip.y < thumbTip.y) {
        gesture = "Paper";
      } else if (indexTip.y < thumbTip.y && middleTip.y < thumbTip.y && ringTip.y > thumbTip.y && pinkyTip.y > thumbTip.y) {
        gesture = "Scissors";
      }

      predictionText.innerText = `Prediction: ${gesture}`;
    }

    // Start video stream
    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        startCountdown();
      } catch (error) {
        console.error('Error accessing camera:', error);
      }
    }

    // Start countdown and capture frame after countdown ends
    function startCountdown() {
      countdown = 5;
      countdownText.innerText = `Countdown: ${countdown}`;
      countdownInterval = setInterval(() => {
        countdown -= 1;
        countdownText.innerText = `Countdown: ${countdown}`;
        if (countdown === 0) {
          clearInterval(countdownInterval);
          hands.send({ image: video }); // Send video frame to MediaPipe for detection
        }
      }, 1000);
    }

    // Restart button logic
    restartButton.addEventListener('click', () => {
      clearInterval(countdownInterval);
      startCountdown();
      predictionText.innerText = 'Prediction: ...';
    });

    // Start the video stream when the page loads
    startVideo();
  </script>
</body>
</html>
